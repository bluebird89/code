{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "# return_X_y默认为False，这种情况下则为一个Bunch对象，改为True，可以直接得到(data, target)\n",
    "X, y = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The digit in the image is 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABAlJREFUeJzt3dFNqmkUhtGPyTRAC1gCtgIlaAlagr1YwqEEacESpIR/\nKpiYSY579DlrXRNeAzz5b0z2btu2BTT99X//AcDXETiECRzCBA5hAocwgUOYwCFM4BAmcAj7+yve\ndLfbJf897nQ6je69vLyMbV0ul7Gt5+fnsa3b7Ta2NW3btt1nr/EEhzCBQ5jAIUzgECZwCBM4hAkc\nwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ9iX\nnC6qmjwltNZah8NhbGu/349tfXx8jG2dz+exrbXWen19Hd37jCc4hAkcwgQOYQKHMIFDmMAhTOAQ\nJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwn78\n6aLj8Ti2NXlKaK217u7uxrbe39/Htn79+jW2Nfn7WMvpImCQwCFM4BAmcAgTOIQJHMIEDmEChzCB\nQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BD242+T\n7ff7sa3r9Tq2tdbsvbBJ05/jn8wTHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAh\nTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmFOF/0Hl8tlbKts8ju73W5jW9+R\nJziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKH\nMIFDmMAhTOAQJnAIEziECRzCfvzposnTNMfjcWxr2uQ5ocnP8fX1dWzrO/IEhzCBQ5jAIUzgECZw\nCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEC\nhzCBQ9hu27bf/6a73e9/039xOBymptbb29vY1lprPT4+jm2dTqexrcnv7P7+fmxr2rZtu89e4wkO\nYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzg\nECZwCBM4hAkcwgQOYQKHMIFD2I+/TTbp4eFhdO/p6Wls63q9jm2dz+exrTK3yeAPJ3AIEziECRzC\nBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAh\nTOAQJnAI+5LTRcD34AkOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJ\nHMIEDmEChzCBQ5jAIUzgECZwCBM4hP0DVJVS9XOb5i4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110811fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 下面完成灰度图的绘制\n",
    "# 灰度显示图像\n",
    "plt.imshow(X[0].reshape(8, 8), cmap='gray');\n",
    "# 关闭坐标轴\n",
    "plt.axis('off')\n",
    "# 格式化打印\n",
    "print('The digit in the image is {}'.format(y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 划分数据为训练集与测试集,添加stratify参数，以使得训练和测试数据集的类分布与整个数据集的类分布相同。\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-304528134e3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy score of the {} is {:.2f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "# 求出Logistic回归的精确度得分\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=5000, random_state=42)\n",
    "clf.fit(self,X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the RandomForestClassifier is 0.96\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier轻松替换LogisticRegression分类器\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multi_class should be either multinomial or ovr, got auto",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a828cabfd7c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} required {} iterations to be fitted'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m         _check_solver_option(self.solver, self.multi_class, self.penalty,\n\u001b[0;32m-> 1222\u001b[0;31m                              self.dual)\n\u001b[0m\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36m_check_solver_option\u001b[0;34m(solver, multi_class, penalty, dual)\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'multinomial'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ovr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         raise ValueError(\"multi_class should be either multinomial or \"\n\u001b[0;32m--> 434\u001b[0;31m                          \"ovr, got %s\" % multi_class)\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'multinomial'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multi_class should be either multinomial or ovr, got auto"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=5000, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "print('{} required {} iterations to be fitted'.format(clf.__class__.__name__, clf.n_iter_[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multi_class should be either multinomial or ovr, got auto",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0ad997f6f827>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy score of the {} is {:.2f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m         _check_solver_option(self.solver, self.multi_class, self.penalty,\n\u001b[0;32m-> 1222\u001b[0;31m                              self.dual)\n\u001b[0m\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36m_check_solver_option\u001b[0;34m(solver, multi_class, penalty, dual)\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'multinomial'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ovr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         raise ValueError(\"multi_class should be either multinomial or \"\n\u001b[0;32m--> 434\u001b[0;31m                          \"ovr, got %s\" % multi_class)\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'multinomial'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multi_class should be either multinomial or ovr, got auto"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=1000, random_state=42)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "accuracy = clf.score(X_test_scaled, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__, accuracy))\n",
    "print('{} required {} iterations to be fitted'.format(clf.__class__.__name__, clf.n_iter_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline(steps=[('scaler', MinMaxScaler()),\n",
    "                       ('clf', LogisticRegression(solver='lbfgs', multi_class='auto', random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(MinMaxScaler(),\n",
    "                     LogisticRegression(solver='lbfgs', multi_class='auto', random_state=42, max_iter=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multi_class should be either multinomial or ovr, got auto",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c4b348942cb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy score of the {} is {:.2f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m         _check_solver_option(self.solver, self.multi_class, self.penalty,\n\u001b[0;32m-> 1222\u001b[0;31m                              self.dual)\n\u001b[0m\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36m_check_solver_option\u001b[0;34m(solver, multi_class, penalty, dual)\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'multinomial'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ovr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         raise ValueError(\"multi_class should be either multinomial or \"\n\u001b[0;32m--> 434\u001b[0;31m                          \"ovr, got %s\" % multi_class)\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'multinomial'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multi_class should be either multinomial or ovr, got auto"
     ]
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "accuracy = pipe.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(pipe.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=1000, multi_class='auto', n_jobs=1,\n",
       "           penalty='l2', random_state=42, solver='lbfgs', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " 'logisticregression__C': 1.0,\n",
       " 'logisticregression__class_weight': None,\n",
       " 'logisticregression__dual': False,\n",
       " 'logisticregression__fit_intercept': True,\n",
       " 'logisticregression__intercept_scaling': 1,\n",
       " 'logisticregression__max_iter': 1000,\n",
       " 'logisticregression__multi_class': 'auto',\n",
       " 'logisticregression__n_jobs': 1,\n",
       " 'logisticregression__penalty': 'l2',\n",
       " 'logisticregression__random_state': 42,\n",
       " 'logisticregression__solver': 'lbfgs',\n",
       " 'logisticregression__tol': 0.0001,\n",
       " 'logisticregression__verbose': 0,\n",
       " 'logisticregression__warm_start': False,\n",
       " 'memory': None,\n",
       " 'minmaxscaler': MinMaxScaler(copy=True, feature_range=(0, 1)),\n",
       " 'minmaxscaler__copy': True,\n",
       " 'minmaxscaler__feature_range': (0, 1),\n",
       " 'steps': [('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       "  ('logisticregression',\n",
       "   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=1000, multi_class='auto', n_jobs=1,\n",
       "             penalty='l2', random_state=42, solver='lbfgs', tol=0.0001,\n",
       "             verbose=0, warm_start=False))]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multi_class should be either multinomial or ovr, got auto",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-da87d08b366f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                      LogisticRegression(solver='lbfgs', multi_class='auto',\n\u001b[1;32m      5\u001b[0m                                         max_iter=1000, random_state=42))\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             return_times=True)\n\u001b[0;32m--> 195\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m         _check_solver_option(self.solver, self.multi_class, self.penalty,\n\u001b[0;32m-> 1222\u001b[0;31m                              self.dual)\n\u001b[0m\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36m_check_solver_option\u001b[0;34m(solver, multi_class, penalty, dual)\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'multinomial'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ovr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         raise ValueError(\"multi_class should be either multinomial or \"\n\u001b[0;32m--> 434\u001b[0;31m                          \"ovr, got %s\" % multi_class)\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'multinomial'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multi_class should be either multinomial or ovr, got auto"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(),\n",
    "                     LogisticRegression(solver='lbfgs', multi_class='auto',\n",
    "                                        max_iter=1000, random_state=42))\n",
    "scores = cross_validate(pipe, X, y, cv=3, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-54a0b9008c11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scores' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_scores = pd.DataFrame(scores)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x105fa0300, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/henry/anaconda/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/henry.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x105fa0300, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/henry/anaconda/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/henry.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import GridSearchCV...turn_train_score=True)\\ngrid.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 1, 5, 2, 53, 31, 228704, tzinfo=tzutc()), 'msg_id': 'C5D562BD707C4B0A944BBFE3B8428E46', 'msg_type': 'execute_request', 'session': 'D99C10FAEDDE476086D74A43BB448CBD', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C5D562BD707C4B0A944BBFE3B8428E46', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'D99C10FAEDDE476086D74A43BB448CBD']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import GridSearchCV...turn_train_score=True)\\ngrid.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 1, 5, 2, 53, 31, 228704, tzinfo=tzutc()), 'msg_id': 'C5D562BD707C4B0A944BBFE3B8428E46', 'msg_type': 'execute_request', 'session': 'D99C10FAEDDE476086D74A43BB448CBD', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C5D562BD707C4B0A944BBFE3B8428E46', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'D99C10FAEDDE476086D74A43BB448CBD'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import GridSearchCV...turn_train_score=True)\\ngrid.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 1, 5, 2, 53, 31, 228704, tzinfo=tzutc()), 'msg_id': 'C5D562BD707C4B0A944BBFE3B8428E46', 'msg_type': 'execute_request', 'session': 'D99C10FAEDDE476086D74A43BB448CBD', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C5D562BD707C4B0A944BBFE3B8428E46', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='from sklearn.model_selection import GridSearchCV...turn_train_score=True)\\ngrid.fit(X_train, y_train)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'from sklearn.model_selection import GridSearchCV...turn_train_score=True)\\ngrid.fit(X_train, y_train)'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('from sklearn.model_selection import GridSearchCV...turn_train_score=True)\\ngrid.fit(X_train, y_train)',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('from sklearn.model_selection import GridSearchCV...turn_train_score=True)\\ngrid.fit(X_train, y_train)',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='from sklearn.model_selection import GridSearchCV...turn_train_score=True)\\ngrid.fit(X_train, y_train)', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-23-8c158b6a11f0>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 116652358, execution_..._before_exec=None error_in_exec=None result=None>)\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n   2807                 code = compiler(mod, cell_name, \"single\")\n-> 2808                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x11664df60, file \"<ipython-input-23-8c158b6a11f0>\", line 9>\n        result = <ExecutionResult object at 116652358, execution_..._before_exec=None error_in_exec=None result=None>\n   2809                     return True\n   2810 \n   2811             # Flush softspace\n   2812             if softspace(sys.stdout, 0):\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x11664df60, file \"<ipython-input-23-8c158b6a11f0>\", line 9>, result=<ExecutionResult object at 116652358, execution_..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x11664df60, file \"<ipython-input-23-8c158b6a11f0>\", line 9>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"get_ipython().magic('matplotlib inline')\", \"get_ipython().magic('matplotlib inline')\\nimport matplotlib.pyplot as plt\", 'from sklearn.datasets import load_digits\\n# retur...data, target)\\nX, y = load_digits(return_X_y=True)', \"# 下面完成灰度图的绘制\\n# 灰度显示图像\\nplt.imshow(X[0].reshape(8,...rint('The digit in the image is {}'.format(y[0]))\", '# 划分数据为训练集与测试集,添加stratify参数，以使得训练和测试数据集的类分布与整个数据...ain_test_split(X, y, stratify=y, random_state=42)', \"# 求出Logistic回归的精确度得分\\nfrom sklearn.linear_model i...{:.2f}'.format(clf.__class__.__name__, accuracy))\", \"# RandomForestClassifier轻松替换LogisticRegression分类...{:.2f}'.format(clf.__class__.__name__, accuracy))\", \"from sklearn.linear_model import LogisticRegress...'.format(clf.__class__.__name__, clf.n_iter_[0]))\", \"rom sklearn.preprocessing import MinMaxScaler\\nfr...'.format(clf.__class__.__name__, clf.n_iter_[0]))\", \"from sklearn.preprocessing import MinMaxScaler\\nf...'.format(clf.__class__.__name__, clf.n_iter_[0]))\", \"from sklearn.pipeline import Pipeline\\n\\npipe = Pi...='lbfgs', multi_class='auto', random_state=42))])\", \"pipe.fit(X_train, y_train)\\naccuracy = pipe.score...:.2f}'.format(pipe.__class__.__name__, accuracy))\", 'rom sklearn.model_selection import cross_validat...lidate(pipe, X, y, cv=3, return_train_score=True)', 'from sklearn.model_selection import cross_valida...lidate(pipe, X, y, cv=3, return_train_score=True)', 'import pandas as pd\\n\\ndf_scores = pd.DataFrame(scores)\\ndf_scores', \"# 求出Logistic回归的精确度得分\\nfrom sklearn.linear_model i...{:.2f}'.format(clf.__class__.__name__, accuracy))\", \"from sklearn.pipeline import make_pipeline\\npipe ...ti_class='auto', random_state=42, max_iter=1000))\", \"pipe.fit(X_train, y_train)\\naccuracy = pipe.score...:.2f}'.format(pipe.__class__.__name__, accuracy))\", \"from sklearn.pipeline import make_pipeline\\npipe ...ti_class='auto', random_state=42, max_iter=1000))\", ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {21: {'logisticregression': LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), 'logisticregression__C': 1.0, 'logisticregression__class_weight': None, 'logisticregression__dual': False, 'logisticregression__fit_intercept': True, 'logisticregression__intercept_scaling': 1, 'logisticregression__max_iter': 1000, 'logisticregression__multi_class': 'auto', 'logisticregression__n_jobs': 1, 'logisticregression__penalty': 'l2', ...}}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'X': array([[  0.,   0.,   5., ...,   0.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), 'X_test': array([[  0.,   0.,   8., ...,   0.,   0.,   0.]...      [  0.,   0.,   0., ...,   2.,   0.,   0.]]), 'X_test_scaled': array([[ 0.    ,  0.    ,  0.5   , ...,  0.    ,....    ,  0.    , ...,  0.125 ,  0.    ,  0.    ]]), ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"get_ipython().magic('matplotlib inline')\", \"get_ipython().magic('matplotlib inline')\\nimport matplotlib.pyplot as plt\", 'from sklearn.datasets import load_digits\\n# retur...data, target)\\nX, y = load_digits(return_X_y=True)', \"# 下面完成灰度图的绘制\\n# 灰度显示图像\\nplt.imshow(X[0].reshape(8,...rint('The digit in the image is {}'.format(y[0]))\", '# 划分数据为训练集与测试集,添加stratify参数，以使得训练和测试数据集的类分布与整个数据...ain_test_split(X, y, stratify=y, random_state=42)', \"# 求出Logistic回归的精确度得分\\nfrom sklearn.linear_model i...{:.2f}'.format(clf.__class__.__name__, accuracy))\", \"# RandomForestClassifier轻松替换LogisticRegression分类...{:.2f}'.format(clf.__class__.__name__, accuracy))\", \"from sklearn.linear_model import LogisticRegress...'.format(clf.__class__.__name__, clf.n_iter_[0]))\", \"rom sklearn.preprocessing import MinMaxScaler\\nfr...'.format(clf.__class__.__name__, clf.n_iter_[0]))\", \"from sklearn.preprocessing import MinMaxScaler\\nf...'.format(clf.__class__.__name__, clf.n_iter_[0]))\", \"from sklearn.pipeline import Pipeline\\n\\npipe = Pi...='lbfgs', multi_class='auto', random_state=42))])\", \"pipe.fit(X_train, y_train)\\naccuracy = pipe.score...:.2f}'.format(pipe.__class__.__name__, accuracy))\", 'rom sklearn.model_selection import cross_validat...lidate(pipe, X, y, cv=3, return_train_score=True)', 'from sklearn.model_selection import cross_valida...lidate(pipe, X, y, cv=3, return_train_score=True)', 'import pandas as pd\\n\\ndf_scores = pd.DataFrame(scores)\\ndf_scores', \"# 求出Logistic回归的精确度得分\\nfrom sklearn.linear_model i...{:.2f}'.format(clf.__class__.__name__, accuracy))\", \"from sklearn.pipeline import make_pipeline\\npipe ...ti_class='auto', random_state=42, max_iter=1000))\", \"pipe.fit(X_train, y_train)\\naccuracy = pipe.score...:.2f}'.format(pipe.__class__.__name__, accuracy))\", \"from sklearn.pipeline import make_pipeline\\npipe ...ti_class='auto', random_state=42, max_iter=1000))\", ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {21: {'logisticregression': LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), 'logisticregression__C': 1.0, 'logisticregression__class_weight': None, 'logisticregression__dual': False, 'logisticregression__fit_intercept': True, 'logisticregression__intercept_scaling': 1, 'logisticregression__max_iter': 1000, 'logisticregression__multi_class': 'auto', 'logisticregression__n_jobs': 1, 'logisticregression__penalty': 'l2', ...}}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'X': array([[  0.,   0.,   5., ...,   0.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), 'X_test': array([[  0.,   0.,   8., ...,   0.,   0.,   0.]...      [  0.,   0.,   0., ...,   2.,   0.,   0.]]), 'X_test_scaled': array([[ 0.    ,  0.    ,  0.5   , ...,  0.    ,....    ,  0.    , ...,  0.125 ,  0.    ,  0.    ]]), ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\n/Users/henry/Workspace/Code/Python/scikit-learn/<ipython-input-23-8c158b6a11f0> in <module>()\n      4                      LogisticRegression(solver='saga', multi_class='auto',\n      5                                         random_state=42, max_iter=5000))\n      6 param_grid = {'logisticregression__C': [0.1, 1.0, 10],\n      7               'logisticregression__penalty': ['l2', 'l1']}\n      8 grid = GridSearchCV(pipe, param_grid=param_grid, cv=3, n_jobs=-1, return_train_score=True)\n----> 9 grid.fit(X_train, y_train)\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=3, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=0), X=array([[  0.,   2.,  12., ...,  15.,   3.,   0.]...      [  0.,   0.,   7., ...,  14.,   6.,   0.]]), y=array([2, 1, 2, ..., 9, 8, 9]), groups=None, **fit_params={})\n    633                                   return_train_score=self.return_train_score,\n    634                                   return_n_test_samples=True,\n    635                                   return_times=True, return_parameters=False,\n    636                                   error_score=self.error_score)\n    637           for parameters, (train, test) in product(candidate_params,\n--> 638                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = array([[  0.,   2.,  12., ...,  15.,   3.,   0.]...      [  0.,   0.,   7., ...,  14.,   6.,   0.]])\n        y = array([2, 1, 2, ..., 9, 8, 9])\n        groups = None\n    639 \n    640         # if one choose to see train score, \"out\" will contain train score info\n    641         if self.return_train_score:\n    642             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sat Jan  5 10:53:31 2019\nPID: 79839                   Python 3.6.2: /Users/henry/anaconda/bin/python\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), array([[  0.,   2.,  12., ...,  15.,   3.,   0.]...      [  0.,   0.,   7., ...,  14.,   6.,   0.]]), array([2, 1, 2, ..., 9, 8, 9]), {'score': <function _passthrough_scorer>}, array([ 342,  361,  370,  372,  381,  385,  389,...1340, 1341, 1342, 1343, 1344,\n       1345, 1346]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...86, 487, 488, 492, 494, 496, 501, 517, 518, 521]), 0, {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), array([[  0.,   2.,  12., ...,  15.,   3.,   0.]...      [  0.,   0.,   7., ...,  14.,   6.,   0.]]), array([2, 1, 2, ..., 9, 8, 9]), {'score': <function _passthrough_scorer>}, array([ 342,  361,  370,  372,  381,  385,  389,...1340, 1341, 1342, 1343, 1344,\n       1345, 1346]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...86, 487, 488, 492, 494, 496, 501, 517, 518, 521]), 0, {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), X=array([[  0.,   2.,  12., ...,  15.,   3.,   0.]...      [  0.,   0.,   7., ...,  14.,   6.,   0.]]), y=array([2, 1, 2, ..., 9, 8, 9]), scorer={'score': <function _passthrough_scorer>}, train=array([ 342,  361,  370,  372,  381,  385,  389,...1340, 1341, 1342, 1343, 1344,\n       1345, 1346]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...86, 487, 488, 492, 494, 496, 501, 517, 518, 521]), verbose=0, parameters={'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2'}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    432 \n    433     try:\n    434         if y_train is None:\n    435             estimator.fit(X_train, **fit_params)\n    436         else:\n--> 437             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No....0001,\n          verbose=0, warm_start=False))])>\n        X_train = array([[  0.,   0.,   5., ...,   8.,   0.,   0.]...      [  0.,   0.,   7., ...,  14.,   6.,   0.]])\n        y_train = array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,... 8, 3, 6, 3, 0, 6, 1, 9, 3, 0, 2, 1, 0, 9, 8, 9])\n        fit_params = {}\n    438 \n    439     except Exception as e:\n    440         # Note fit time as time until error\n    441         fit_time = time.time() - start_time\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), X=array([[  0.,   0.,   5., ...,   8.,   0.,   0.]...      [  0.,   0.,   7., ...,  14.,   6.,   0.]]), y=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,... 8, 3, 6, 3, 0, 6, 1, 9, 3, 0, 2, 1, 0, 9, 8, 9]), **fit_params={})\n    254         self : Pipeline\n    255             This estimator\n    256         \"\"\"\n    257         Xt, fit_params = self._fit(X, y, **fit_params)\n    258         if self._final_estimator is not None:\n--> 259             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method LogisticRegression.fit of Logistic...l=0.0001,\n          verbose=0, warm_start=False)>\n        Xt = array([[ 0.    ,  0.    ,  0.3125, ...,  0.5   ,....    ,  0.4375, ...,  0.875 ,  0.375 ,  0.    ]])\n        y = array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,... 8, 3, 6, 3, 0, 6, 1, 9, 3, 0, 2, 1, 0, 9, 8, 9])\n        fit_params = {}\n    260         return self\n    261 \n    262     def fit_transform(self, X, y=None, **fit_params):\n    263         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py in fit(self=LogisticRegression(C=0.1, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), X=array([[ 0.    ,  0.    ,  0.3125, ...,  0.5   ,....    ,  0.4375, ...,  0.875 ,  0.375 ,  0.    ]]), y=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,... 8, 3, 6, 3, 0, 6, 1, 9, 3, 0, 2, 1, 0, 9, 8, 9]), sample_weight=None)\n   1217         check_classification_targets(y)\n   1218         self.classes_ = np.unique(y)\n   1219         n_samples, n_features = X.shape\n   1220 \n   1221         _check_solver_option(self.solver, self.multi_class, self.penalty,\n-> 1222                              self.dual)\n        self.dual = False\n   1223 \n   1224         if self.solver == 'liblinear':\n   1225             if self.n_jobs != 1:\n   1226                 warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py in _check_solver_option(solver='saga', multi_class='auto', penalty='l2', dual=False)\n    429                          \"newton-cg, lbfgs, sag and saga solvers, got %s\"\n    430                          % solver)\n    431 \n    432     if multi_class not in ['multinomial', 'ovr']:\n    433         raise ValueError(\"multi_class should be either multinomial or \"\n--> 434                          \"ovr, got %s\" % multi_class)\n        multi_class = 'auto'\n    435 \n    436     if multi_class == 'multinomial' and solver == 'liblinear':\n    437         raise ValueError(\"Solver %s does not support \"\n    438                          \"a multinomial backend.\" % solver)\n\nValueError: multi_class should be either multinomial or ovr, got auto\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 437, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py\", line 259, in fit\n    self._final_estimator.fit(Xt, y, **fit_params)\n  File \"/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\", line 1222, in fit\n    self.dual)\n  File \"/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\", line 434, in _check_solver_option\n    \"ovr, got %s\" % multi_class)\nValueError: multi_class should be either multinomial or ovr, got auto\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/henry/anaconda/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Sat Jan  5 10:53:31 2019\nPID: 79839                   Python 3.6.2: /Users/henry/anaconda/bin/python\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), array([[  0.,   2.,  12., ...,  15.,   3.,   0.]...      [  0.,   0.,   7., ...,  14.,   6.,   0.]]), array([2, 1, 2, ..., 9, 8, 9]), {'score': <function _passthrough_scorer>}, array([ 342,  361,  370,  372,  381,  385,  389,...1340, 1341, 1342, 1343, 1344,\n       1345, 1346]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...86, 487, 488, 492, 494, 496, 501, 517, 518, 521]), 0, {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), array([[  0.,   2.,  12., ...,  15.,   3.,   0.]...      [  0.,   0.,   7., ...,  14.,   6.,   0.]]), array([2, 1, 2, ..., 9, 8, 9]), {'score': <function _passthrough_scorer>}, array([ 342,  361,  370,  372,  381,  385,  389,...1340, 1341, 1342, 1343, 1344,\n       1345, 1346]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...86, 487, 488, 492, 494, 496, 501, 517, 518, 521]), 0, {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), X=array([[  0.,   2.,  12., ...,  15.,   3.,   0.]...      [  0.,   0.,   7., ...,  14.,   6.,   0.]]), y=array([2, 1, 2, ..., 9, 8, 9]), scorer={'score': <function _passthrough_scorer>}, train=array([ 342,  361,  370,  372,  381,  385,  389,...1340, 1341, 1342, 1343, 1344,\n       1345, 1346]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...86, 487, 488, 492, 494, 496, 501, 517, 518, 521]), verbose=0, parameters={'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2'}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    432 \n    433     try:\n    434         if y_train is None:\n    435             estimator.fit(X_train, **fit_params)\n    436         else:\n--> 437             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No....0001,\n          verbose=0, warm_start=False))])>\n        X_train = array([[  0.,   0.,   5., ...,   8.,   0.,   0.]...      [  0.,   0.,   7., ...,  14.,   6.,   0.]])\n        y_train = array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,... 8, 3, 6, 3, 0, 6, 1, 9, 3, 0, 2, 1, 0, 9, 8, 9])\n        fit_params = {}\n    438 \n    439     except Exception as e:\n    440         # Note fit time as time until error\n    441         fit_time = time.time() - start_time\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), X=array([[  0.,   0.,   5., ...,   8.,   0.,   0.]...      [  0.,   0.,   7., ...,  14.,   6.,   0.]]), y=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,... 8, 3, 6, 3, 0, 6, 1, 9, 3, 0, 2, 1, 0, 9, 8, 9]), **fit_params={})\n    254         self : Pipeline\n    255             This estimator\n    256         \"\"\"\n    257         Xt, fit_params = self._fit(X, y, **fit_params)\n    258         if self._final_estimator is not None:\n--> 259             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method LogisticRegression.fit of Logistic...l=0.0001,\n          verbose=0, warm_start=False)>\n        Xt = array([[ 0.    ,  0.    ,  0.3125, ...,  0.5   ,....    ,  0.4375, ...,  0.875 ,  0.375 ,  0.    ]])\n        y = array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,... 8, 3, 6, 3, 0, 6, 1, 9, 3, 0, 2, 1, 0, 9, 8, 9])\n        fit_params = {}\n    260         return self\n    261 \n    262     def fit_transform(self, X, y=None, **fit_params):\n    263         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py in fit(self=LogisticRegression(C=0.1, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), X=array([[ 0.    ,  0.    ,  0.3125, ...,  0.5   ,....    ,  0.4375, ...,  0.875 ,  0.375 ,  0.    ]]), y=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,... 8, 3, 6, 3, 0, 6, 1, 9, 3, 0, 2, 1, 0, 9, 8, 9]), sample_weight=None)\n   1217         check_classification_targets(y)\n   1218         self.classes_ = np.unique(y)\n   1219         n_samples, n_features = X.shape\n   1220 \n   1221         _check_solver_option(self.solver, self.multi_class, self.penalty,\n-> 1222                              self.dual)\n        self.dual = False\n   1223 \n   1224         if self.solver == 'liblinear':\n   1225             if self.n_jobs != 1:\n   1226                 warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py in _check_solver_option(solver='saga', multi_class='auto', penalty='l2', dual=False)\n    429                          \"newton-cg, lbfgs, sag and saga solvers, got %s\"\n    430                          % solver)\n    431 \n    432     if multi_class not in ['multinomial', 'ovr']:\n    433         raise ValueError(\"multi_class should be either multinomial or \"\n--> 434                          \"ovr, got %s\" % multi_class)\n        multi_class = 'auto'\n    435 \n    436     if multi_class == 'multinomial' and solver == 'liblinear':\n    437         raise ValueError(\"Solver %s does not support \"\n    438                          \"a multinomial backend.\" % solver)\n\nValueError: multi_class should be either multinomial or ovr, got auto\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Sat Jan  5 10:53:31 2019\nPID: 79839                   Python 3.6.2: /Users/henry/anaconda/bin/python\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), array([[  0.,   2.,  12., ...,  15.,   3.,   0.]...      [  0.,   0.,   7., ...,  14.,   6.,   0.]]), array([2, 1, 2, ..., 9, 8, 9]), {'score': <function _passthrough_scorer>}, array([ 342,  361,  370,  372,  381,  385,  389,...1340, 1341, 1342, 1343, 1344,\n       1345, 1346]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...86, 487, 488, 492, 494, 496, 501, 517, 518, 521]), 0, {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), array([[  0.,   2.,  12., ...,  15.,   3.,   0.]...      [  0.,   0.,   7., ...,  14.,   6.,   0.]]), array([2, 1, 2, ..., 9, 8, 9]), {'score': <function _passthrough_scorer>}, array([ 342,  361,  370,  372,  381,  385,  389,...1340, 1341, 1342, 1343, 1344,\n       1345, 1346]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...86, 487, 488, 492, 494, 496, 501, 517, 518, 521]), 0, {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), X=array([[  0.,   2.,  12., ...,  15.,   3.,   0.]...      [  0.,   0.,   7., ...,  14.,   6.,   0.]]), y=array([2, 1, 2, ..., 9, 8, 9]), scorer={'score': <function _passthrough_scorer>}, train=array([ 342,  361,  370,  372,  381,  385,  389,...1340, 1341, 1342, 1343, 1344,\n       1345, 1346]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...86, 487, 488, 492, 494, 496, 501, 517, 518, 521]), verbose=0, parameters={'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2'}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    432 \n    433     try:\n    434         if y_train is None:\n    435             estimator.fit(X_train, **fit_params)\n    436         else:\n--> 437             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No....0001,\n          verbose=0, warm_start=False))])>\n        X_train = array([[  0.,   0.,   5., ...,   8.,   0.,   0.]...      [  0.,   0.,   7., ...,  14.,   6.,   0.]])\n        y_train = array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,... 8, 3, 6, 3, 0, 6, 1, 9, 3, 0, 2, 1, 0, 9, 8, 9])\n        fit_params = {}\n    438 \n    439     except Exception as e:\n    440         # Note fit time as time until error\n    441         fit_time = time.time() - start_time\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), X=array([[  0.,   0.,   5., ...,   8.,   0.,   0.]...      [  0.,   0.,   7., ...,  14.,   6.,   0.]]), y=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,... 8, 3, 6, 3, 0, 6, 1, 9, 3, 0, 2, 1, 0, 9, 8, 9]), **fit_params={})\n    254         self : Pipeline\n    255             This estimator\n    256         \"\"\"\n    257         Xt, fit_params = self._fit(X, y, **fit_params)\n    258         if self._final_estimator is not None:\n--> 259             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method LogisticRegression.fit of Logistic...l=0.0001,\n          verbose=0, warm_start=False)>\n        Xt = array([[ 0.    ,  0.    ,  0.3125, ...,  0.5   ,....    ,  0.4375, ...,  0.875 ,  0.375 ,  0.    ]])\n        y = array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,... 8, 3, 6, 3, 0, 6, 1, 9, 3, 0, 2, 1, 0, 9, 8, 9])\n        fit_params = {}\n    260         return self\n    261 \n    262     def fit_transform(self, X, y=None, **fit_params):\n    263         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py in fit(self=LogisticRegression(C=0.1, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), X=array([[ 0.    ,  0.    ,  0.3125, ...,  0.5   ,....    ,  0.4375, ...,  0.875 ,  0.375 ,  0.    ]]), y=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,... 8, 3, 6, 3, 0, 6, 1, 9, 3, 0, 2, 1, 0, 9, 8, 9]), sample_weight=None)\n   1217         check_classification_targets(y)\n   1218         self.classes_ = np.unique(y)\n   1219         n_samples, n_features = X.shape\n   1220 \n   1221         _check_solver_option(self.solver, self.multi_class, self.penalty,\n-> 1222                              self.dual)\n        self.dual = False\n   1223 \n   1224         if self.solver == 'liblinear':\n   1225             if self.n_jobs != 1:\n   1226                 warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py in _check_solver_option(solver='saga', multi_class='auto', penalty='l2', dual=False)\n    429                          \"newton-cg, lbfgs, sag and saga solvers, got %s\"\n    430                          % solver)\n    431 \n    432     if multi_class not in ['multinomial', 'ovr']:\n    433         raise ValueError(\"multi_class should be either multinomial or \"\n--> 434                          \"ovr, got %s\" % multi_class)\n        multi_class = 'auto'\n    435 \n    436     if multi_class == 'multinomial' and solver == 'liblinear':\n    437         raise ValueError(\"Solver %s does not support \"\n    438                          \"a multinomial backend.\" % solver)\n\nValueError: multi_class should be either multinomial or ovr, got auto\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-8c158b6a11f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m               'logisticregression__penalty': ['l2', 'l1']}\n\u001b[1;32m      8\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    636\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    637\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 638\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x105fa0300, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/henry/anaconda/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/henry.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x105fa0300, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/henry/anaconda/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/henry.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import GridSearchCV...turn_train_score=True)\\ngrid.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 1, 5, 2, 53, 31, 228704, tzinfo=tzutc()), 'msg_id': 'C5D562BD707C4B0A944BBFE3B8428E46', 'msg_type': 'execute_request', 'session': 'D99C10FAEDDE476086D74A43BB448CBD', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C5D562BD707C4B0A944BBFE3B8428E46', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'D99C10FAEDDE476086D74A43BB448CBD']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import GridSearchCV...turn_train_score=True)\\ngrid.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 1, 5, 2, 53, 31, 228704, tzinfo=tzutc()), 'msg_id': 'C5D562BD707C4B0A944BBFE3B8428E46', 'msg_type': 'execute_request', 'session': 'D99C10FAEDDE476086D74A43BB448CBD', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C5D562BD707C4B0A944BBFE3B8428E46', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'D99C10FAEDDE476086D74A43BB448CBD'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import GridSearchCV...turn_train_score=True)\\ngrid.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 1, 5, 2, 53, 31, 228704, tzinfo=tzutc()), 'msg_id': 'C5D562BD707C4B0A944BBFE3B8428E46', 'msg_type': 'execute_request', 'session': 'D99C10FAEDDE476086D74A43BB448CBD', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C5D562BD707C4B0A944BBFE3B8428E46', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='from sklearn.model_selection import GridSearchCV...turn_train_score=True)\\ngrid.fit(X_train, y_train)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'from sklearn.model_selection import GridSearchCV...turn_train_score=True)\\ngrid.fit(X_train, y_train)'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('from sklearn.model_selection import GridSearchCV...turn_train_score=True)\\ngrid.fit(X_train, y_train)',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('from sklearn.model_selection import GridSearchCV...turn_train_score=True)\\ngrid.fit(X_train, y_train)',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='from sklearn.model_selection import GridSearchCV...turn_train_score=True)\\ngrid.fit(X_train, y_train)', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-23-8c158b6a11f0>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 116652358, execution_..._before_exec=None error_in_exec=None result=None>)\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n   2807                 code = compiler(mod, cell_name, \"single\")\n-> 2808                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x11664df60, file \"<ipython-input-23-8c158b6a11f0>\", line 9>\n        result = <ExecutionResult object at 116652358, execution_..._before_exec=None error_in_exec=None result=None>\n   2809                     return True\n   2810 \n   2811             # Flush softspace\n   2812             if softspace(sys.stdout, 0):\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x11664df60, file \"<ipython-input-23-8c158b6a11f0>\", line 9>, result=<ExecutionResult object at 116652358, execution_..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x11664df60, file \"<ipython-input-23-8c158b6a11f0>\", line 9>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"get_ipython().magic('matplotlib inline')\", \"get_ipython().magic('matplotlib inline')\\nimport matplotlib.pyplot as plt\", 'from sklearn.datasets import load_digits\\n# retur...data, target)\\nX, y = load_digits(return_X_y=True)', \"# 下面完成灰度图的绘制\\n# 灰度显示图像\\nplt.imshow(X[0].reshape(8,...rint('The digit in the image is {}'.format(y[0]))\", '# 划分数据为训练集与测试集,添加stratify参数，以使得训练和测试数据集的类分布与整个数据...ain_test_split(X, y, stratify=y, random_state=42)', \"# 求出Logistic回归的精确度得分\\nfrom sklearn.linear_model i...{:.2f}'.format(clf.__class__.__name__, accuracy))\", \"# RandomForestClassifier轻松替换LogisticRegression分类...{:.2f}'.format(clf.__class__.__name__, accuracy))\", \"from sklearn.linear_model import LogisticRegress...'.format(clf.__class__.__name__, clf.n_iter_[0]))\", \"rom sklearn.preprocessing import MinMaxScaler\\nfr...'.format(clf.__class__.__name__, clf.n_iter_[0]))\", \"from sklearn.preprocessing import MinMaxScaler\\nf...'.format(clf.__class__.__name__, clf.n_iter_[0]))\", \"from sklearn.pipeline import Pipeline\\n\\npipe = Pi...='lbfgs', multi_class='auto', random_state=42))])\", \"pipe.fit(X_train, y_train)\\naccuracy = pipe.score...:.2f}'.format(pipe.__class__.__name__, accuracy))\", 'rom sklearn.model_selection import cross_validat...lidate(pipe, X, y, cv=3, return_train_score=True)', 'from sklearn.model_selection import cross_valida...lidate(pipe, X, y, cv=3, return_train_score=True)', 'import pandas as pd\\n\\ndf_scores = pd.DataFrame(scores)\\ndf_scores', \"# 求出Logistic回归的精确度得分\\nfrom sklearn.linear_model i...{:.2f}'.format(clf.__class__.__name__, accuracy))\", \"from sklearn.pipeline import make_pipeline\\npipe ...ti_class='auto', random_state=42, max_iter=1000))\", \"pipe.fit(X_train, y_train)\\naccuracy = pipe.score...:.2f}'.format(pipe.__class__.__name__, accuracy))\", \"from sklearn.pipeline import make_pipeline\\npipe ...ti_class='auto', random_state=42, max_iter=1000))\", ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {21: {'logisticregression': LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), 'logisticregression__C': 1.0, 'logisticregression__class_weight': None, 'logisticregression__dual': False, 'logisticregression__fit_intercept': True, 'logisticregression__intercept_scaling': 1, 'logisticregression__max_iter': 1000, 'logisticregression__multi_class': 'auto', 'logisticregression__n_jobs': 1, 'logisticregression__penalty': 'l2', ...}}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'X': array([[  0.,   0.,   5., ...,   0.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), 'X_test': array([[  0.,   0.,   8., ...,   0.,   0.,   0.]...      [  0.,   0.,   0., ...,   2.,   0.,   0.]]), 'X_test_scaled': array([[ 0.    ,  0.    ,  0.5   , ...,  0.    ,....    ,  0.    , ...,  0.125 ,  0.    ,  0.    ]]), ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"get_ipython().magic('matplotlib inline')\", \"get_ipython().magic('matplotlib inline')\\nimport matplotlib.pyplot as plt\", 'from sklearn.datasets import load_digits\\n# retur...data, target)\\nX, y = load_digits(return_X_y=True)', \"# 下面完成灰度图的绘制\\n# 灰度显示图像\\nplt.imshow(X[0].reshape(8,...rint('The digit in the image is {}'.format(y[0]))\", '# 划分数据为训练集与测试集,添加stratify参数，以使得训练和测试数据集的类分布与整个数据...ain_test_split(X, y, stratify=y, random_state=42)', \"# 求出Logistic回归的精确度得分\\nfrom sklearn.linear_model i...{:.2f}'.format(clf.__class__.__name__, accuracy))\", \"# RandomForestClassifier轻松替换LogisticRegression分类...{:.2f}'.format(clf.__class__.__name__, accuracy))\", \"from sklearn.linear_model import LogisticRegress...'.format(clf.__class__.__name__, clf.n_iter_[0]))\", \"rom sklearn.preprocessing import MinMaxScaler\\nfr...'.format(clf.__class__.__name__, clf.n_iter_[0]))\", \"from sklearn.preprocessing import MinMaxScaler\\nf...'.format(clf.__class__.__name__, clf.n_iter_[0]))\", \"from sklearn.pipeline import Pipeline\\n\\npipe = Pi...='lbfgs', multi_class='auto', random_state=42))])\", \"pipe.fit(X_train, y_train)\\naccuracy = pipe.score...:.2f}'.format(pipe.__class__.__name__, accuracy))\", 'rom sklearn.model_selection import cross_validat...lidate(pipe, X, y, cv=3, return_train_score=True)', 'from sklearn.model_selection import cross_valida...lidate(pipe, X, y, cv=3, return_train_score=True)', 'import pandas as pd\\n\\ndf_scores = pd.DataFrame(scores)\\ndf_scores', \"# 求出Logistic回归的精确度得分\\nfrom sklearn.linear_model i...{:.2f}'.format(clf.__class__.__name__, accuracy))\", \"from sklearn.pipeline import make_pipeline\\npipe ...ti_class='auto', random_state=42, max_iter=1000))\", \"pipe.fit(X_train, y_train)\\naccuracy = pipe.score...:.2f}'.format(pipe.__class__.__name__, accuracy))\", \"from sklearn.pipeline import make_pipeline\\npipe ...ti_class='auto', random_state=42, max_iter=1000))\", ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {21: {'logisticregression': LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), 'logisticregression__C': 1.0, 'logisticregression__class_weight': None, 'logisticregression__dual': False, 'logisticregression__fit_intercept': True, 'logisticregression__intercept_scaling': 1, 'logisticregression__max_iter': 1000, 'logisticregression__multi_class': 'auto', 'logisticregression__n_jobs': 1, 'logisticregression__penalty': 'l2', ...}}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'X': array([[  0.,   0.,   5., ...,   0.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), 'X_test': array([[  0.,   0.,   8., ...,   0.,   0.,   0.]...      [  0.,   0.,   0., ...,   2.,   0.,   0.]]), 'X_test_scaled': array([[ 0.    ,  0.    ,  0.5   , ...,  0.    ,....    ,  0.    , ...,  0.125 ,  0.    ,  0.    ]]), ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\n/Users/henry/Workspace/Code/Python/scikit-learn/<ipython-input-23-8c158b6a11f0> in <module>()\n      4                      LogisticRegression(solver='saga', multi_class='auto',\n      5                                         random_state=42, max_iter=5000))\n      6 param_grid = {'logisticregression__C': [0.1, 1.0, 10],\n      7               'logisticregression__penalty': ['l2', 'l1']}\n      8 grid = GridSearchCV(pipe, param_grid=param_grid, cv=3, n_jobs=-1, return_train_score=True)\n----> 9 grid.fit(X_train, y_train)\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=3, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=0), X=array([[  0.,   2.,  12., ...,  15.,   3.,   0.]...      [  0.,   0.,   7., ...,  14.,   6.,   0.]]), y=array([2, 1, 2, ..., 9, 8, 9]), groups=None, **fit_params={})\n    633                                   return_train_score=self.return_train_score,\n    634                                   return_n_test_samples=True,\n    635                                   return_times=True, return_parameters=False,\n    636                                   error_score=self.error_score)\n    637           for parameters, (train, test) in product(candidate_params,\n--> 638                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = array([[  0.,   2.,  12., ...,  15.,   3.,   0.]...      [  0.,   0.,   7., ...,  14.,   6.,   0.]])\n        y = array([2, 1, 2, ..., 9, 8, 9])\n        groups = None\n    639 \n    640         # if one choose to see train score, \"out\" will contain train score info\n    641         if self.return_train_score:\n    642             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sat Jan  5 10:53:31 2019\nPID: 79839                   Python 3.6.2: /Users/henry/anaconda/bin/python\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), array([[  0.,   2.,  12., ...,  15.,   3.,   0.]...      [  0.,   0.,   7., ...,  14.,   6.,   0.]]), array([2, 1, 2, ..., 9, 8, 9]), {'score': <function _passthrough_scorer>}, array([ 342,  361,  370,  372,  381,  385,  389,...1340, 1341, 1342, 1343, 1344,\n       1345, 1346]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...86, 487, 488, 492, 494, 496, 501, 517, 518, 521]), 0, {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), array([[  0.,   2.,  12., ...,  15.,   3.,   0.]...      [  0.,   0.,   7., ...,  14.,   6.,   0.]]), array([2, 1, 2, ..., 9, 8, 9]), {'score': <function _passthrough_scorer>}, array([ 342,  361,  370,  372,  381,  385,  389,...1340, 1341, 1342, 1343, 1344,\n       1345, 1346]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...86, 487, 488, 492, 494, 496, 501, 517, 518, 521]), 0, {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), X=array([[  0.,   2.,  12., ...,  15.,   3.,   0.]...      [  0.,   0.,   7., ...,  14.,   6.,   0.]]), y=array([2, 1, 2, ..., 9, 8, 9]), scorer={'score': <function _passthrough_scorer>}, train=array([ 342,  361,  370,  372,  381,  385,  389,...1340, 1341, 1342, 1343, 1344,\n       1345, 1346]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...86, 487, 488, 492, 494, 496, 501, 517, 518, 521]), verbose=0, parameters={'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2'}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    432 \n    433     try:\n    434         if y_train is None:\n    435             estimator.fit(X_train, **fit_params)\n    436         else:\n--> 437             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No....0001,\n          verbose=0, warm_start=False))])>\n        X_train = array([[  0.,   0.,   5., ...,   8.,   0.,   0.]...      [  0.,   0.,   7., ...,  14.,   6.,   0.]])\n        y_train = array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,... 8, 3, 6, 3, 0, 6, 1, 9, 3, 0, 2, 1, 0, 9, 8, 9])\n        fit_params = {}\n    438 \n    439     except Exception as e:\n    440         # Note fit time as time until error\n    441         fit_time = time.time() - start_time\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), X=array([[  0.,   0.,   5., ...,   8.,   0.,   0.]...      [  0.,   0.,   7., ...,  14.,   6.,   0.]]), y=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,... 8, 3, 6, 3, 0, 6, 1, 9, 3, 0, 2, 1, 0, 9, 8, 9]), **fit_params={})\n    254         self : Pipeline\n    255             This estimator\n    256         \"\"\"\n    257         Xt, fit_params = self._fit(X, y, **fit_params)\n    258         if self._final_estimator is not None:\n--> 259             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method LogisticRegression.fit of Logistic...l=0.0001,\n          verbose=0, warm_start=False)>\n        Xt = array([[ 0.    ,  0.    ,  0.3125, ...,  0.5   ,....    ,  0.4375, ...,  0.875 ,  0.375 ,  0.    ]])\n        y = array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,... 8, 3, 6, 3, 0, 6, 1, 9, 3, 0, 2, 1, 0, 9, 8, 9])\n        fit_params = {}\n    260         return self\n    261 \n    262     def fit_transform(self, X, y=None, **fit_params):\n    263         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py in fit(self=LogisticRegression(C=0.1, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), X=array([[ 0.    ,  0.    ,  0.3125, ...,  0.5   ,....    ,  0.4375, ...,  0.875 ,  0.375 ,  0.    ]]), y=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,... 8, 3, 6, 3, 0, 6, 1, 9, 3, 0, 2, 1, 0, 9, 8, 9]), sample_weight=None)\n   1217         check_classification_targets(y)\n   1218         self.classes_ = np.unique(y)\n   1219         n_samples, n_features = X.shape\n   1220 \n   1221         _check_solver_option(self.solver, self.multi_class, self.penalty,\n-> 1222                              self.dual)\n        self.dual = False\n   1223 \n   1224         if self.solver == 'liblinear':\n   1225             if self.n_jobs != 1:\n   1226                 warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py in _check_solver_option(solver='saga', multi_class='auto', penalty='l2', dual=False)\n    429                          \"newton-cg, lbfgs, sag and saga solvers, got %s\"\n    430                          % solver)\n    431 \n    432     if multi_class not in ['multinomial', 'ovr']:\n    433         raise ValueError(\"multi_class should be either multinomial or \"\n--> 434                          \"ovr, got %s\" % multi_class)\n        multi_class = 'auto'\n    435 \n    436     if multi_class == 'multinomial' and solver == 'liblinear':\n    437         raise ValueError(\"Solver %s does not support \"\n    438                          \"a multinomial backend.\" % solver)\n\nValueError: multi_class should be either multinomial or ovr, got auto\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(),\n",
    "                     LogisticRegression(solver='saga', multi_class='auto',\n",
    "                                        random_state=42, max_iter=5000))\n",
    "param_grid = {'logisticregression__C': [0.1, 1.0, 10],\n",
    "              'logisticregression__penalty': ['l2', 'l1']}\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=3, n_jobs=-1, return_train_score=True)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'cv_results_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-f2fdcdc61fe4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_grid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'cv_results_'"
     ]
    }
   ],
   "source": [
    "df_grid = pd.DataFrame(grid.cv_results_)\n",
    "df_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x105fa0300, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/henry/anaconda/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/henry.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x105fa0300, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/henry/anaconda/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/henry.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"import pandas as pd\\nfrom sklearn.preprocessing i...)\\nscores[['train_score', 'test_score']].boxplot()\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 1, 5, 2, 54, 8, 804264, tzinfo=tzutc()), 'msg_id': '5E579DE94C784097AD7641E87994792B', 'msg_type': 'execute_request', 'session': 'D99C10FAEDDE476086D74A43BB448CBD', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '5E579DE94C784097AD7641E87994792B', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'D99C10FAEDDE476086D74A43BB448CBD']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"import pandas as pd\\nfrom sklearn.preprocessing i...)\\nscores[['train_score', 'test_score']].boxplot()\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 1, 5, 2, 54, 8, 804264, tzinfo=tzutc()), 'msg_id': '5E579DE94C784097AD7641E87994792B', 'msg_type': 'execute_request', 'session': 'D99C10FAEDDE476086D74A43BB448CBD', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '5E579DE94C784097AD7641E87994792B', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'D99C10FAEDDE476086D74A43BB448CBD'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"import pandas as pd\\nfrom sklearn.preprocessing i...)\\nscores[['train_score', 'test_score']].boxplot()\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 1, 5, 2, 54, 8, 804264, tzinfo=tzutc()), 'msg_id': '5E579DE94C784097AD7641E87994792B', 'msg_type': 'execute_request', 'session': 'D99C10FAEDDE476086D74A43BB448CBD', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '5E579DE94C784097AD7641E87994792B', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"import pandas as pd\\nfrom sklearn.preprocessing i...)\\nscores[['train_score', 'test_score']].boxplot()\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"import pandas as pd\\nfrom sklearn.preprocessing i...)\\nscores[['train_score', 'test_score']].boxplot()\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"import pandas as pd\\nfrom sklearn.preprocessing i...)\\nscores[['train_score', 'test_score']].boxplot()\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"import pandas as pd\\nfrom sklearn.preprocessing i...)\\nscores[['train_score', 'test_score']].boxplot()\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"import pandas as pd\\nfrom sklearn.preprocessing i...)\\nscores[['train_score', 'test_score']].boxplot()\", store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Import object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-25-511d2f55ed93>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1107a1b70, execution_..._before_exec=None error_in_exec=None result=None>)\n   2797 \n   2798         try:\n   2799             for i, node in enumerate(to_run_exec):\n   2800                 mod = ast.Module([node])\n   2801                 code = compiler(mod, cell_name, \"exec\")\n-> 2802                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x1106fc390, file \"<ipython-input-25-511d2f55ed93>\", line 13>\n        result = <ExecutionResult object at 1107a1b70, execution_..._before_exec=None error_in_exec=None result=None>\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x1106fc390, file \"<ipython-input-25-511d2f55ed93>\", line 13>, result=<ExecutionResult object at 1107a1b70, execution_..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x1106fc390, file \"<ipython-input-25-511d2f55ed93>\", line 13>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"get_ipython().magic('matplotlib inline')\", \"get_ipython().magic('matplotlib inline')\\nimport matplotlib.pyplot as plt\", 'from sklearn.datasets import load_digits\\n# retur...data, target)\\nX, y = load_digits(return_X_y=True)', \"# 下面完成灰度图的绘制\\n# 灰度显示图像\\nplt.imshow(X[0].reshape(8,...rint('The digit in the image is {}'.format(y[0]))\", '# 划分数据为训练集与测试集,添加stratify参数，以使得训练和测试数据集的类分布与整个数据...ain_test_split(X, y, stratify=y, random_state=42)', \"# 求出Logistic回归的精确度得分\\nfrom sklearn.linear_model i...{:.2f}'.format(clf.__class__.__name__, accuracy))\", \"# RandomForestClassifier轻松替换LogisticRegression分类...{:.2f}'.format(clf.__class__.__name__, accuracy))\", \"from sklearn.linear_model import LogisticRegress...'.format(clf.__class__.__name__, clf.n_iter_[0]))\", \"rom sklearn.preprocessing import MinMaxScaler\\nfr...'.format(clf.__class__.__name__, clf.n_iter_[0]))\", \"from sklearn.preprocessing import MinMaxScaler\\nf...'.format(clf.__class__.__name__, clf.n_iter_[0]))\", \"from sklearn.pipeline import Pipeline\\n\\npipe = Pi...='lbfgs', multi_class='auto', random_state=42))])\", \"pipe.fit(X_train, y_train)\\naccuracy = pipe.score...:.2f}'.format(pipe.__class__.__name__, accuracy))\", 'rom sklearn.model_selection import cross_validat...lidate(pipe, X, y, cv=3, return_train_score=True)', 'from sklearn.model_selection import cross_valida...lidate(pipe, X, y, cv=3, return_train_score=True)', 'import pandas as pd\\n\\ndf_scores = pd.DataFrame(scores)\\ndf_scores', \"# 求出Logistic回归的精确度得分\\nfrom sklearn.linear_model i...{:.2f}'.format(clf.__class__.__name__, accuracy))\", \"from sklearn.pipeline import make_pipeline\\npipe ...ti_class='auto', random_state=42, max_iter=1000))\", \"pipe.fit(X_train, y_train)\\naccuracy = pipe.score...:.2f}'.format(pipe.__class__.__name__, accuracy))\", \"from sklearn.pipeline import make_pipeline\\npipe ...ti_class='auto', random_state=42, max_iter=1000))\", ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {21: {'logisticregression': LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), 'logisticregression__C': 1.0, 'logisticregression__class_weight': None, 'logisticregression__dual': False, 'logisticregression__fit_intercept': True, 'logisticregression__intercept_scaling': 1, 'logisticregression__max_iter': 1000, 'logisticregression__multi_class': 'auto', 'logisticregression__n_jobs': 1, 'logisticregression__penalty': 'l2', ...}}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'X': array([[  0.,   0.,   5., ...,   0.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), 'X_test': array([[  0.,   0.,   8., ...,   0.,   0.,   0.]...      [  0.,   0.,   0., ...,   2.,   0.,   0.]]), 'X_test_scaled': array([[ 0.    ,  0.    ,  0.5   , ...,  0.    ,....    ,  0.    , ...,  0.125 ,  0.    ,  0.    ]]), ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"get_ipython().magic('matplotlib inline')\", \"get_ipython().magic('matplotlib inline')\\nimport matplotlib.pyplot as plt\", 'from sklearn.datasets import load_digits\\n# retur...data, target)\\nX, y = load_digits(return_X_y=True)', \"# 下面完成灰度图的绘制\\n# 灰度显示图像\\nplt.imshow(X[0].reshape(8,...rint('The digit in the image is {}'.format(y[0]))\", '# 划分数据为训练集与测试集,添加stratify参数，以使得训练和测试数据集的类分布与整个数据...ain_test_split(X, y, stratify=y, random_state=42)', \"# 求出Logistic回归的精确度得分\\nfrom sklearn.linear_model i...{:.2f}'.format(clf.__class__.__name__, accuracy))\", \"# RandomForestClassifier轻松替换LogisticRegression分类...{:.2f}'.format(clf.__class__.__name__, accuracy))\", \"from sklearn.linear_model import LogisticRegress...'.format(clf.__class__.__name__, clf.n_iter_[0]))\", \"rom sklearn.preprocessing import MinMaxScaler\\nfr...'.format(clf.__class__.__name__, clf.n_iter_[0]))\", \"from sklearn.preprocessing import MinMaxScaler\\nf...'.format(clf.__class__.__name__, clf.n_iter_[0]))\", \"from sklearn.pipeline import Pipeline\\n\\npipe = Pi...='lbfgs', multi_class='auto', random_state=42))])\", \"pipe.fit(X_train, y_train)\\naccuracy = pipe.score...:.2f}'.format(pipe.__class__.__name__, accuracy))\", 'rom sklearn.model_selection import cross_validat...lidate(pipe, X, y, cv=3, return_train_score=True)', 'from sklearn.model_selection import cross_valida...lidate(pipe, X, y, cv=3, return_train_score=True)', 'import pandas as pd\\n\\ndf_scores = pd.DataFrame(scores)\\ndf_scores', \"# 求出Logistic回归的精确度得分\\nfrom sklearn.linear_model i...{:.2f}'.format(clf.__class__.__name__, accuracy))\", \"from sklearn.pipeline import make_pipeline\\npipe ...ti_class='auto', random_state=42, max_iter=1000))\", \"pipe.fit(X_train, y_train)\\naccuracy = pipe.score...:.2f}'.format(pipe.__class__.__name__, accuracy))\", \"from sklearn.pipeline import make_pipeline\\npipe ...ti_class='auto', random_state=42, max_iter=1000))\", ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {21: {'logisticregression': LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), 'logisticregression__C': 1.0, 'logisticregression__class_weight': None, 'logisticregression__dual': False, 'logisticregression__fit_intercept': True, 'logisticregression__intercept_scaling': 1, 'logisticregression__max_iter': 1000, 'logisticregression__multi_class': 'auto', 'logisticregression__n_jobs': 1, 'logisticregression__penalty': 'l2', ...}}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'X': array([[  0.,   0.,   5., ...,   0.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), 'X_test': array([[  0.,   0.,   8., ...,   0.,   0.,   0.]...      [  0.,   0.,   0., ...,   2.,   0.,   0.]]), 'X_test_scaled': array([[ 0.    ,  0.    ,  0.5   , ...,  0.    ,....    ,  0.    , ...,  0.125 ,  0.    ,  0.    ]]), ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\n/Users/henry/Workspace/Code/Python/scikit-learn/<ipython-input-25-511d2f55ed93> in <module>()\n      8 pipe = make_pipeline(MinMaxScaler(),\n      9                      LogisticRegression(solver='saga', multi_class='auto', random_state=42, max_iter=5000))\n     10 param_grid = {'logisticregression__C': [0.1, 1.0, 10],\n     11               'logisticregression__penalty': ['l2', 'l1']}\n     12 grid = GridSearchCV(pipe, param_grid=param_grid, cv=3, n_jobs=-1)\n---> 13 scores = pd.DataFrame(cross_validate(grid, X, y, cv=3, n_jobs=-1, return_train_score=True))\n     14 scores[['train_score', 'test_score']].boxplot()\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=GridSearchCV(cv=3, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=0), X=array([[  0.,   0.,   5., ...,   0.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=True)\n    190     scores = parallel(\n    191         delayed(_fit_and_score)(\n    192             clone(estimator), X, y, scorers, train, test, verbose, None,\n    193             fit_params, return_train_score=return_train_score,\n    194             return_times=True)\n--> 195         for train, test in cv.split(X, y, groups))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = array([[  0.,   0.,   5., ...,   0.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]])\n        y = array([0, 1, 2, ..., 8, 9, 8])\n        groups = None\n    196 \n    197     if return_train_score:\n    198         train_scores, test_scores, fit_times, score_times = zip(*scores)\n    199         train_scores = _aggregate_score_dicts(train_scores)\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object cross_validate.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sat Jan  5 10:54:08 2019\nPID: 81022                   Python 3.6.2: /Users/henry/anaconda/bin/python\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (GridSearchCV(cv=3, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=0), array([[  0.,   0.,   5., ...,   0.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 588,  591,  593, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 601, 602, 603, 604,\n       608, 613, 616, 626]), 0, None, None), {'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GridSearchCV(cv=3, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=0), array([[  0.,   0.,   5., ...,   0.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 588,  591,  593, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 601, 602, 603, 604,\n       608, 613, 616, 626]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=GridSearchCV(cv=3, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=0), X=array([[  0.,   0.,   5., ...,   0.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), scorer={'score': <function _passthrough_scorer>}, train=array([ 588,  591,  593, ..., 1794, 1795, 1796]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 601, 602, 603, 604,\n       608, 613, 616, 626]), verbose=0, parameters=None, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    432 \n    433     try:\n    434         if y_train is None:\n    435             estimator.fit(X_train, **fit_params)\n    436         else:\n--> 437             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseSearchCV.fit of GridSearchCV(c...rain_score=True,\n       scoring=None, verbose=0)>\n        X_train = array([[  0.,   0.,   0., ...,   3.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]])\n        y_train = array([0, 2, 2, ..., 8, 9, 8])\n        fit_params = {}\n    438 \n    439     except Exception as e:\n    440         # Note fit time as time until error\n    441         fit_time = time.time() - start_time\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=3, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=0), X=array([[  0.,   0.,   0., ...,   3.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), y=array([0, 2, 2, ..., 8, 9, 8]), groups=None, **fit_params={})\n    633                                   return_train_score=self.return_train_score,\n    634                                   return_n_test_samples=True,\n    635                                   return_times=True, return_parameters=False,\n    636                                   error_score=self.error_score)\n    637           for parameters, (train, test) in product(candidate_params,\n--> 638                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = array([[  0.,   0.,   0., ...,   3.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]])\n        y = array([0, 2, 2, ..., 8, 9, 8])\n        groups = None\n    639 \n    640         # if one choose to see train score, \"out\" will contain train score info\n    641         if self.return_train_score:\n    642             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=-1)>\n        iterator = <generator object BaseSearchCV.fit.<locals>.<genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=-1), iterator=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=-1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=-1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), array([[  0.,   0.,   0., ...,   3.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), array([0, 2, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 384,  390,  395,  397,  398,  402,  403,...1188, 1189, 1190, 1191, 1192, 1193,\n       1194]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...94, 396, 399, 400, 401, 404, 407, 408, 409, 410]), 0, {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), array([[  0.,   0.,   0., ...,   3.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), array([0, 2, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 384,  390,  395,  397,  398,  402,  403,...1188, 1189, 1190, 1191, 1192, 1193,\n       1194]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...94, 396, 399, 400, 401, 404, 407, 408, 409, 410]), 0, {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), X=array([[  0.,   0.,   0., ...,   3.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), y=array([0, 2, 2, ..., 8, 9, 8]), scorer={'score': <function _passthrough_scorer>}, train=array([ 384,  390,  395,  397,  398,  402,  403,...1188, 1189, 1190, 1191, 1192, 1193,\n       1194]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...94, 396, 399, 400, 401, 404, 407, 408, 409, 410]), verbose=0, parameters={'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2'}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    432 \n    433     try:\n    434         if y_train is None:\n    435             estimator.fit(X_train, **fit_params)\n    436         else:\n--> 437             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No....0001,\n          verbose=0, warm_start=False))])>\n        X_train = array([[  0.,   3.,  15., ...,  16.,  16.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]])\n        y_train = array([2, 3, 8, 3, 1, 3, 6, 6, 1, 7, 2, 8, 2, 2,...2, 5, 7,\n       9, 5, 4, 8, 8, 4, 9, 0, 8, 9, 8])\n        fit_params = {}\n    438 \n    439     except Exception as e:\n    440         # Note fit time as time until error\n    441         fit_time = time.time() - start_time\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), X=array([[  0.,   3.,  15., ...,  16.,  16.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), y=array([2, 3, 8, 3, 1, 3, 6, 6, 1, 7, 2, 8, 2, 2,...2, 5, 7,\n       9, 5, 4, 8, 8, 4, 9, 0, 8, 9, 8]), **fit_params={})\n    254         self : Pipeline\n    255             This estimator\n    256         \"\"\"\n    257         Xt, fit_params = self._fit(X, y, **fit_params)\n    258         if self._final_estimator is not None:\n--> 259             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method LogisticRegression.fit of Logistic...l=0.0001,\n          verbose=0, warm_start=False)>\n        Xt = array([[ 0.    ,  0.375 ,  0.9375, ...,  1.    ,....    ,  0.625 , ...,  0.75  ,  0.0625,  0.    ]])\n        y = array([2, 3, 8, 3, 1, 3, 6, 6, 1, 7, 2, 8, 2, 2,...2, 5, 7,\n       9, 5, 4, 8, 8, 4, 9, 0, 8, 9, 8])\n        fit_params = {}\n    260         return self\n    261 \n    262     def fit_transform(self, X, y=None, **fit_params):\n    263         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py in fit(self=LogisticRegression(C=0.1, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), X=array([[ 0.    ,  0.375 ,  0.9375, ...,  1.    ,....    ,  0.625 , ...,  0.75  ,  0.0625,  0.    ]]), y=array([2, 3, 8, 3, 1, 3, 6, 6, 1, 7, 2, 8, 2, 2,...2, 5, 7,\n       9, 5, 4, 8, 8, 4, 9, 0, 8, 9, 8]), sample_weight=None)\n   1217         check_classification_targets(y)\n   1218         self.classes_ = np.unique(y)\n   1219         n_samples, n_features = X.shape\n   1220 \n   1221         _check_solver_option(self.solver, self.multi_class, self.penalty,\n-> 1222                              self.dual)\n        self.dual = False\n   1223 \n   1224         if self.solver == 'liblinear':\n   1225             if self.n_jobs != 1:\n   1226                 warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py in _check_solver_option(solver='saga', multi_class='auto', penalty='l2', dual=False)\n    429                          \"newton-cg, lbfgs, sag and saga solvers, got %s\"\n    430                          % solver)\n    431 \n    432     if multi_class not in ['multinomial', 'ovr']:\n    433         raise ValueError(\"multi_class should be either multinomial or \"\n--> 434                          \"ovr, got %s\" % multi_class)\n        multi_class = 'auto'\n    435 \n    436     if multi_class == 'multinomial' and solver == 'liblinear':\n    437         raise ValueError(\"Solver %s does not support \"\n    438                          \"a multinomial backend.\" % solver)\n\nValueError: multi_class should be either multinomial or ovr, got auto\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 437, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\", line 638, in fit\n    cv.split(X, y, groups)))\n  File \"/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 779, in __call__\n    while self.dispatch_one_batch(iterator):\n  File \"/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 625, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 588, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 111, in apply_async\n    result = ImmediateResult(func)\n  File \"/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 332, in __init__\n    self.results = batch()\n  File \"/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 437, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py\", line 259, in fit\n    self._final_estimator.fit(Xt, y, **fit_params)\n  File \"/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\", line 1222, in fit\n    self.dual)\n  File \"/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\", line 434, in _check_solver_option\n    \"ovr, got %s\" % multi_class)\nValueError: multi_class should be either multinomial or ovr, got auto\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/henry/anaconda/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Sat Jan  5 10:54:08 2019\nPID: 81022                   Python 3.6.2: /Users/henry/anaconda/bin/python\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (GridSearchCV(cv=3, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=0), array([[  0.,   0.,   5., ...,   0.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 588,  591,  593, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 601, 602, 603, 604,\n       608, 613, 616, 626]), 0, None, None), {'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GridSearchCV(cv=3, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=0), array([[  0.,   0.,   5., ...,   0.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 588,  591,  593, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 601, 602, 603, 604,\n       608, 613, 616, 626]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=GridSearchCV(cv=3, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=0), X=array([[  0.,   0.,   5., ...,   0.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), scorer={'score': <function _passthrough_scorer>}, train=array([ 588,  591,  593, ..., 1794, 1795, 1796]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 601, 602, 603, 604,\n       608, 613, 616, 626]), verbose=0, parameters=None, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    432 \n    433     try:\n    434         if y_train is None:\n    435             estimator.fit(X_train, **fit_params)\n    436         else:\n--> 437             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseSearchCV.fit of GridSearchCV(c...rain_score=True,\n       scoring=None, verbose=0)>\n        X_train = array([[  0.,   0.,   0., ...,   3.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]])\n        y_train = array([0, 2, 2, ..., 8, 9, 8])\n        fit_params = {}\n    438 \n    439     except Exception as e:\n    440         # Note fit time as time until error\n    441         fit_time = time.time() - start_time\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=3, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=0), X=array([[  0.,   0.,   0., ...,   3.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), y=array([0, 2, 2, ..., 8, 9, 8]), groups=None, **fit_params={})\n    633                                   return_train_score=self.return_train_score,\n    634                                   return_n_test_samples=True,\n    635                                   return_times=True, return_parameters=False,\n    636                                   error_score=self.error_score)\n    637           for parameters, (train, test) in product(candidate_params,\n--> 638                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = array([[  0.,   0.,   0., ...,   3.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]])\n        y = array([0, 2, 2, ..., 8, 9, 8])\n        groups = None\n    639 \n    640         # if one choose to see train score, \"out\" will contain train score info\n    641         if self.return_train_score:\n    642             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=-1)>\n        iterator = <generator object BaseSearchCV.fit.<locals>.<genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=-1), iterator=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=-1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=-1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), array([[  0.,   0.,   0., ...,   3.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), array([0, 2, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 384,  390,  395,  397,  398,  402,  403,...1188, 1189, 1190, 1191, 1192, 1193,\n       1194]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...94, 396, 399, 400, 401, 404, 407, 408, 409, 410]), 0, {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), array([[  0.,   0.,   0., ...,   3.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), array([0, 2, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 384,  390,  395,  397,  398,  402,  403,...1188, 1189, 1190, 1191, 1192, 1193,\n       1194]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...94, 396, 399, 400, 401, 404, 407, 408, 409, 410]), 0, {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), X=array([[  0.,   0.,   0., ...,   3.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), y=array([0, 2, 2, ..., 8, 9, 8]), scorer={'score': <function _passthrough_scorer>}, train=array([ 384,  390,  395,  397,  398,  402,  403,...1188, 1189, 1190, 1191, 1192, 1193,\n       1194]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...94, 396, 399, 400, 401, 404, 407, 408, 409, 410]), verbose=0, parameters={'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2'}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    432 \n    433     try:\n    434         if y_train is None:\n    435             estimator.fit(X_train, **fit_params)\n    436         else:\n--> 437             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No....0001,\n          verbose=0, warm_start=False))])>\n        X_train = array([[  0.,   3.,  15., ...,  16.,  16.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]])\n        y_train = array([2, 3, 8, 3, 1, 3, 6, 6, 1, 7, 2, 8, 2, 2,...2, 5, 7,\n       9, 5, 4, 8, 8, 4, 9, 0, 8, 9, 8])\n        fit_params = {}\n    438 \n    439     except Exception as e:\n    440         # Note fit time as time until error\n    441         fit_time = time.time() - start_time\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), X=array([[  0.,   3.,  15., ...,  16.,  16.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), y=array([2, 3, 8, 3, 1, 3, 6, 6, 1, 7, 2, 8, 2, 2,...2, 5, 7,\n       9, 5, 4, 8, 8, 4, 9, 0, 8, 9, 8]), **fit_params={})\n    254         self : Pipeline\n    255             This estimator\n    256         \"\"\"\n    257         Xt, fit_params = self._fit(X, y, **fit_params)\n    258         if self._final_estimator is not None:\n--> 259             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method LogisticRegression.fit of Logistic...l=0.0001,\n          verbose=0, warm_start=False)>\n        Xt = array([[ 0.    ,  0.375 ,  0.9375, ...,  1.    ,....    ,  0.625 , ...,  0.75  ,  0.0625,  0.    ]])\n        y = array([2, 3, 8, 3, 1, 3, 6, 6, 1, 7, 2, 8, 2, 2,...2, 5, 7,\n       9, 5, 4, 8, 8, 4, 9, 0, 8, 9, 8])\n        fit_params = {}\n    260         return self\n    261 \n    262     def fit_transform(self, X, y=None, **fit_params):\n    263         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py in fit(self=LogisticRegression(C=0.1, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), X=array([[ 0.    ,  0.375 ,  0.9375, ...,  1.    ,....    ,  0.625 , ...,  0.75  ,  0.0625,  0.    ]]), y=array([2, 3, 8, 3, 1, 3, 6, 6, 1, 7, 2, 8, 2, 2,...2, 5, 7,\n       9, 5, 4, 8, 8, 4, 9, 0, 8, 9, 8]), sample_weight=None)\n   1217         check_classification_targets(y)\n   1218         self.classes_ = np.unique(y)\n   1219         n_samples, n_features = X.shape\n   1220 \n   1221         _check_solver_option(self.solver, self.multi_class, self.penalty,\n-> 1222                              self.dual)\n        self.dual = False\n   1223 \n   1224         if self.solver == 'liblinear':\n   1225             if self.n_jobs != 1:\n   1226                 warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py in _check_solver_option(solver='saga', multi_class='auto', penalty='l2', dual=False)\n    429                          \"newton-cg, lbfgs, sag and saga solvers, got %s\"\n    430                          % solver)\n    431 \n    432     if multi_class not in ['multinomial', 'ovr']:\n    433         raise ValueError(\"multi_class should be either multinomial or \"\n--> 434                          \"ovr, got %s\" % multi_class)\n        multi_class = 'auto'\n    435 \n    436     if multi_class == 'multinomial' and solver == 'liblinear':\n    437         raise ValueError(\"Solver %s does not support \"\n    438                          \"a multinomial backend.\" % solver)\n\nValueError: multi_class should be either multinomial or ovr, got auto\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Sat Jan  5 10:54:08 2019\nPID: 81022                   Python 3.6.2: /Users/henry/anaconda/bin/python\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (GridSearchCV(cv=3, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=0), array([[  0.,   0.,   5., ...,   0.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 588,  591,  593, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 601, 602, 603, 604,\n       608, 613, 616, 626]), 0, None, None), {'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GridSearchCV(cv=3, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=0), array([[  0.,   0.,   5., ...,   0.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 588,  591,  593, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 601, 602, 603, 604,\n       608, 613, 616, 626]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=GridSearchCV(cv=3, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=0), X=array([[  0.,   0.,   5., ...,   0.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), scorer={'score': <function _passthrough_scorer>}, train=array([ 588,  591,  593, ..., 1794, 1795, 1796]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 601, 602, 603, 604,\n       608, 613, 616, 626]), verbose=0, parameters=None, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    432 \n    433     try:\n    434         if y_train is None:\n    435             estimator.fit(X_train, **fit_params)\n    436         else:\n--> 437             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseSearchCV.fit of GridSearchCV(c...rain_score=True,\n       scoring=None, verbose=0)>\n        X_train = array([[  0.,   0.,   0., ...,   3.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]])\n        y_train = array([0, 2, 2, ..., 8, 9, 8])\n        fit_params = {}\n    438 \n    439     except Exception as e:\n    440         # Note fit time as time until error\n    441         fit_time = time.time() - start_time\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=3, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=0), X=array([[  0.,   0.,   0., ...,   3.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), y=array([0, 2, 2, ..., 8, 9, 8]), groups=None, **fit_params={})\n    633                                   return_train_score=self.return_train_score,\n    634                                   return_n_test_samples=True,\n    635                                   return_times=True, return_parameters=False,\n    636                                   error_score=self.error_score)\n    637           for parameters, (train, test) in product(candidate_params,\n--> 638                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = array([[  0.,   0.,   0., ...,   3.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]])\n        y = array([0, 2, 2, ..., 8, 9, 8])\n        groups = None\n    639 \n    640         # if one choose to see train score, \"out\" will contain train score info\n    641         if self.return_train_score:\n    642             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=-1)>\n        iterator = <generator object BaseSearchCV.fit.<locals>.<genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=-1), iterator=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=-1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=-1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), array([[  0.,   0.,   0., ...,   3.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), array([0, 2, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 384,  390,  395,  397,  398,  402,  403,...1188, 1189, 1190, 1191, 1192, 1193,\n       1194]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...94, 396, 399, 400, 401, 404, 407, 408, 409, 410]), 0, {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), array([[  0.,   0.,   0., ...,   3.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), array([0, 2, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 384,  390,  395,  397,  398,  402,  403,...1188, 1189, 1190, 1191, 1192, 1193,\n       1194]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...94, 396, 399, 400, 401, 404, 407, 408, 409, 410]), 0, {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), X=array([[  0.,   0.,   0., ...,   3.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), y=array([0, 2, 2, ..., 8, 9, 8]), scorer={'score': <function _passthrough_scorer>}, train=array([ 384,  390,  395,  397,  398,  402,  403,...1188, 1189, 1190, 1191, 1192, 1193,\n       1194]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...94, 396, 399, 400, 401, 404, 407, 408, 409, 410]), verbose=0, parameters={'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2'}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    432 \n    433     try:\n    434         if y_train is None:\n    435             estimator.fit(X_train, **fit_params)\n    436         else:\n--> 437             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No....0001,\n          verbose=0, warm_start=False))])>\n        X_train = array([[  0.,   3.,  15., ...,  16.,  16.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]])\n        y_train = array([2, 3, 8, 3, 1, 3, 6, 6, 1, 7, 2, 8, 2, 2,...2, 5, 7,\n       9, 5, 4, 8, 8, 4, 9, 0, 8, 9, 8])\n        fit_params = {}\n    438 \n    439     except Exception as e:\n    440         # Note fit time as time until error\n    441         fit_time = time.time() - start_time\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), X=array([[  0.,   3.,  15., ...,  16.,  16.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), y=array([2, 3, 8, 3, 1, 3, 6, 6, 1, 7, 2, 8, 2, 2,...2, 5, 7,\n       9, 5, 4, 8, 8, 4, 9, 0, 8, 9, 8]), **fit_params={})\n    254         self : Pipeline\n    255             This estimator\n    256         \"\"\"\n    257         Xt, fit_params = self._fit(X, y, **fit_params)\n    258         if self._final_estimator is not None:\n--> 259             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method LogisticRegression.fit of Logistic...l=0.0001,\n          verbose=0, warm_start=False)>\n        Xt = array([[ 0.    ,  0.375 ,  0.9375, ...,  1.    ,....    ,  0.625 , ...,  0.75  ,  0.0625,  0.    ]])\n        y = array([2, 3, 8, 3, 1, 3, 6, 6, 1, 7, 2, 8, 2, 2,...2, 5, 7,\n       9, 5, 4, 8, 8, 4, 9, 0, 8, 9, 8])\n        fit_params = {}\n    260         return self\n    261 \n    262     def fit_transform(self, X, y=None, **fit_params):\n    263         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py in fit(self=LogisticRegression(C=0.1, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), X=array([[ 0.    ,  0.375 ,  0.9375, ...,  1.    ,....    ,  0.625 , ...,  0.75  ,  0.0625,  0.    ]]), y=array([2, 3, 8, 3, 1, 3, 6, 6, 1, 7, 2, 8, 2, 2,...2, 5, 7,\n       9, 5, 4, 8, 8, 4, 9, 0, 8, 9, 8]), sample_weight=None)\n   1217         check_classification_targets(y)\n   1218         self.classes_ = np.unique(y)\n   1219         n_samples, n_features = X.shape\n   1220 \n   1221         _check_solver_option(self.solver, self.multi_class, self.penalty,\n-> 1222                              self.dual)\n        self.dual = False\n   1223 \n   1224         if self.solver == 'liblinear':\n   1225             if self.n_jobs != 1:\n   1226                 warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py in _check_solver_option(solver='saga', multi_class='auto', penalty='l2', dual=False)\n    429                          \"newton-cg, lbfgs, sag and saga solvers, got %s\"\n    430                          % solver)\n    431 \n    432     if multi_class not in ['multinomial', 'ovr']:\n    433         raise ValueError(\"multi_class should be either multinomial or \"\n--> 434                          \"ovr, got %s\" % multi_class)\n        multi_class = 'auto'\n    435 \n    436     if multi_class == 'multinomial' and solver == 'liblinear':\n    437         raise ValueError(\"Solver %s does not support \"\n    438                          \"a multinomial backend.\" % solver)\n\nValueError: multi_class should be either multinomial or ovr, got auto\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-511d2f55ed93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m               'logisticregression__penalty': ['l2', 'l1']}\n\u001b[1;32m     12\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             return_times=True)\n\u001b[0;32m--> 195\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x105fa0300, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/henry/anaconda/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/henry.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x105fa0300, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/henry/anaconda/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/henry.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"import pandas as pd\\nfrom sklearn.preprocessing i...)\\nscores[['train_score', 'test_score']].boxplot()\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 1, 5, 2, 54, 8, 804264, tzinfo=tzutc()), 'msg_id': '5E579DE94C784097AD7641E87994792B', 'msg_type': 'execute_request', 'session': 'D99C10FAEDDE476086D74A43BB448CBD', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '5E579DE94C784097AD7641E87994792B', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'D99C10FAEDDE476086D74A43BB448CBD']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"import pandas as pd\\nfrom sklearn.preprocessing i...)\\nscores[['train_score', 'test_score']].boxplot()\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 1, 5, 2, 54, 8, 804264, tzinfo=tzutc()), 'msg_id': '5E579DE94C784097AD7641E87994792B', 'msg_type': 'execute_request', 'session': 'D99C10FAEDDE476086D74A43BB448CBD', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '5E579DE94C784097AD7641E87994792B', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'D99C10FAEDDE476086D74A43BB448CBD'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"import pandas as pd\\nfrom sklearn.preprocessing i...)\\nscores[['train_score', 'test_score']].boxplot()\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 1, 5, 2, 54, 8, 804264, tzinfo=tzutc()), 'msg_id': '5E579DE94C784097AD7641E87994792B', 'msg_type': 'execute_request', 'session': 'D99C10FAEDDE476086D74A43BB448CBD', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '5E579DE94C784097AD7641E87994792B', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"import pandas as pd\\nfrom sklearn.preprocessing i...)\\nscores[['train_score', 'test_score']].boxplot()\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"import pandas as pd\\nfrom sklearn.preprocessing i...)\\nscores[['train_score', 'test_score']].boxplot()\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"import pandas as pd\\nfrom sklearn.preprocessing i...)\\nscores[['train_score', 'test_score']].boxplot()\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"import pandas as pd\\nfrom sklearn.preprocessing i...)\\nscores[['train_score', 'test_score']].boxplot()\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"import pandas as pd\\nfrom sklearn.preprocessing i...)\\nscores[['train_score', 'test_score']].boxplot()\", store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Import object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-25-511d2f55ed93>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1107a1b70, execution_..._before_exec=None error_in_exec=None result=None>)\n   2797 \n   2798         try:\n   2799             for i, node in enumerate(to_run_exec):\n   2800                 mod = ast.Module([node])\n   2801                 code = compiler(mod, cell_name, \"exec\")\n-> 2802                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x1106fc390, file \"<ipython-input-25-511d2f55ed93>\", line 13>\n        result = <ExecutionResult object at 1107a1b70, execution_..._before_exec=None error_in_exec=None result=None>\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x1106fc390, file \"<ipython-input-25-511d2f55ed93>\", line 13>, result=<ExecutionResult object at 1107a1b70, execution_..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x1106fc390, file \"<ipython-input-25-511d2f55ed93>\", line 13>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"get_ipython().magic('matplotlib inline')\", \"get_ipython().magic('matplotlib inline')\\nimport matplotlib.pyplot as plt\", 'from sklearn.datasets import load_digits\\n# retur...data, target)\\nX, y = load_digits(return_X_y=True)', \"# 下面完成灰度图的绘制\\n# 灰度显示图像\\nplt.imshow(X[0].reshape(8,...rint('The digit in the image is {}'.format(y[0]))\", '# 划分数据为训练集与测试集,添加stratify参数，以使得训练和测试数据集的类分布与整个数据...ain_test_split(X, y, stratify=y, random_state=42)', \"# 求出Logistic回归的精确度得分\\nfrom sklearn.linear_model i...{:.2f}'.format(clf.__class__.__name__, accuracy))\", \"# RandomForestClassifier轻松替换LogisticRegression分类...{:.2f}'.format(clf.__class__.__name__, accuracy))\", \"from sklearn.linear_model import LogisticRegress...'.format(clf.__class__.__name__, clf.n_iter_[0]))\", \"rom sklearn.preprocessing import MinMaxScaler\\nfr...'.format(clf.__class__.__name__, clf.n_iter_[0]))\", \"from sklearn.preprocessing import MinMaxScaler\\nf...'.format(clf.__class__.__name__, clf.n_iter_[0]))\", \"from sklearn.pipeline import Pipeline\\n\\npipe = Pi...='lbfgs', multi_class='auto', random_state=42))])\", \"pipe.fit(X_train, y_train)\\naccuracy = pipe.score...:.2f}'.format(pipe.__class__.__name__, accuracy))\", 'rom sklearn.model_selection import cross_validat...lidate(pipe, X, y, cv=3, return_train_score=True)', 'from sklearn.model_selection import cross_valida...lidate(pipe, X, y, cv=3, return_train_score=True)', 'import pandas as pd\\n\\ndf_scores = pd.DataFrame(scores)\\ndf_scores', \"# 求出Logistic回归的精确度得分\\nfrom sklearn.linear_model i...{:.2f}'.format(clf.__class__.__name__, accuracy))\", \"from sklearn.pipeline import make_pipeline\\npipe ...ti_class='auto', random_state=42, max_iter=1000))\", \"pipe.fit(X_train, y_train)\\naccuracy = pipe.score...:.2f}'.format(pipe.__class__.__name__, accuracy))\", \"from sklearn.pipeline import make_pipeline\\npipe ...ti_class='auto', random_state=42, max_iter=1000))\", ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {21: {'logisticregression': LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), 'logisticregression__C': 1.0, 'logisticregression__class_weight': None, 'logisticregression__dual': False, 'logisticregression__fit_intercept': True, 'logisticregression__intercept_scaling': 1, 'logisticregression__max_iter': 1000, 'logisticregression__multi_class': 'auto', 'logisticregression__n_jobs': 1, 'logisticregression__penalty': 'l2', ...}}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'X': array([[  0.,   0.,   5., ...,   0.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), 'X_test': array([[  0.,   0.,   8., ...,   0.,   0.,   0.]...      [  0.,   0.,   0., ...,   2.,   0.,   0.]]), 'X_test_scaled': array([[ 0.    ,  0.    ,  0.5   , ...,  0.    ,....    ,  0.    , ...,  0.125 ,  0.    ,  0.    ]]), ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"get_ipython().magic('matplotlib inline')\", \"get_ipython().magic('matplotlib inline')\\nimport matplotlib.pyplot as plt\", 'from sklearn.datasets import load_digits\\n# retur...data, target)\\nX, y = load_digits(return_X_y=True)', \"# 下面完成灰度图的绘制\\n# 灰度显示图像\\nplt.imshow(X[0].reshape(8,...rint('The digit in the image is {}'.format(y[0]))\", '# 划分数据为训练集与测试集,添加stratify参数，以使得训练和测试数据集的类分布与整个数据...ain_test_split(X, y, stratify=y, random_state=42)', \"# 求出Logistic回归的精确度得分\\nfrom sklearn.linear_model i...{:.2f}'.format(clf.__class__.__name__, accuracy))\", \"# RandomForestClassifier轻松替换LogisticRegression分类...{:.2f}'.format(clf.__class__.__name__, accuracy))\", \"from sklearn.linear_model import LogisticRegress...'.format(clf.__class__.__name__, clf.n_iter_[0]))\", \"rom sklearn.preprocessing import MinMaxScaler\\nfr...'.format(clf.__class__.__name__, clf.n_iter_[0]))\", \"from sklearn.preprocessing import MinMaxScaler\\nf...'.format(clf.__class__.__name__, clf.n_iter_[0]))\", \"from sklearn.pipeline import Pipeline\\n\\npipe = Pi...='lbfgs', multi_class='auto', random_state=42))])\", \"pipe.fit(X_train, y_train)\\naccuracy = pipe.score...:.2f}'.format(pipe.__class__.__name__, accuracy))\", 'rom sklearn.model_selection import cross_validat...lidate(pipe, X, y, cv=3, return_train_score=True)', 'from sklearn.model_selection import cross_valida...lidate(pipe, X, y, cv=3, return_train_score=True)', 'import pandas as pd\\n\\ndf_scores = pd.DataFrame(scores)\\ndf_scores', \"# 求出Logistic回归的精确度得分\\nfrom sklearn.linear_model i...{:.2f}'.format(clf.__class__.__name__, accuracy))\", \"from sklearn.pipeline import make_pipeline\\npipe ...ti_class='auto', random_state=42, max_iter=1000))\", \"pipe.fit(X_train, y_train)\\naccuracy = pipe.score...:.2f}'.format(pipe.__class__.__name__, accuracy))\", \"from sklearn.pipeline import make_pipeline\\npipe ...ti_class='auto', random_state=42, max_iter=1000))\", ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {21: {'logisticregression': LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), 'logisticregression__C': 1.0, 'logisticregression__class_weight': None, 'logisticregression__dual': False, 'logisticregression__fit_intercept': True, 'logisticregression__intercept_scaling': 1, 'logisticregression__max_iter': 1000, 'logisticregression__multi_class': 'auto', 'logisticregression__n_jobs': 1, 'logisticregression__penalty': 'l2', ...}}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'X': array([[  0.,   0.,   5., ...,   0.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), 'X_test': array([[  0.,   0.,   8., ...,   0.,   0.,   0.]...      [  0.,   0.,   0., ...,   2.,   0.,   0.]]), 'X_test_scaled': array([[ 0.    ,  0.    ,  0.5   , ...,  0.    ,....    ,  0.    , ...,  0.125 ,  0.    ,  0.    ]]), ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\n/Users/henry/Workspace/Code/Python/scikit-learn/<ipython-input-25-511d2f55ed93> in <module>()\n      8 pipe = make_pipeline(MinMaxScaler(),\n      9                      LogisticRegression(solver='saga', multi_class='auto', random_state=42, max_iter=5000))\n     10 param_grid = {'logisticregression__C': [0.1, 1.0, 10],\n     11               'logisticregression__penalty': ['l2', 'l1']}\n     12 grid = GridSearchCV(pipe, param_grid=param_grid, cv=3, n_jobs=-1)\n---> 13 scores = pd.DataFrame(cross_validate(grid, X, y, cv=3, n_jobs=-1, return_train_score=True))\n     14 scores[['train_score', 'test_score']].boxplot()\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=GridSearchCV(cv=3, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=0), X=array([[  0.,   0.,   5., ...,   0.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), groups=None, scoring=None, cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=True)\n    190     scores = parallel(\n    191         delayed(_fit_and_score)(\n    192             clone(estimator), X, y, scorers, train, test, verbose, None,\n    193             fit_params, return_train_score=return_train_score,\n    194             return_times=True)\n--> 195         for train, test in cv.split(X, y, groups))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = array([[  0.,   0.,   5., ...,   0.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]])\n        y = array([0, 1, 2, ..., 8, 9, 8])\n        groups = None\n    196 \n    197     if return_train_score:\n    198         train_scores, test_scores, fit_times, score_times = zip(*scores)\n    199         train_scores = _aggregate_score_dicts(train_scores)\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object cross_validate.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sat Jan  5 10:54:08 2019\nPID: 81022                   Python 3.6.2: /Users/henry/anaconda/bin/python\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (GridSearchCV(cv=3, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=0), array([[  0.,   0.,   5., ...,   0.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 588,  591,  593, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 601, 602, 603, 604,\n       608, 613, 616, 626]), 0, None, None), {'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GridSearchCV(cv=3, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=0), array([[  0.,   0.,   5., ...,   0.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), array([0, 1, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 588,  591,  593, ..., 1794, 1795, 1796]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 601, 602, 603, 604,\n       608, 613, 616, 626]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=GridSearchCV(cv=3, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=0), X=array([[  0.,   0.,   5., ...,   0.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), y=array([0, 1, 2, ..., 8, 9, 8]), scorer={'score': <function _passthrough_scorer>}, train=array([ 588,  591,  593, ..., 1794, 1795, 1796]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 601, 602, 603, 604,\n       608, 613, 616, 626]), verbose=0, parameters=None, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    432 \n    433     try:\n    434         if y_train is None:\n    435             estimator.fit(X_train, **fit_params)\n    436         else:\n--> 437             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseSearchCV.fit of GridSearchCV(c...rain_score=True,\n       scoring=None, verbose=0)>\n        X_train = array([[  0.,   0.,   0., ...,   3.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]])\n        y_train = array([0, 2, 2, ..., 8, 9, 8])\n        fit_params = {}\n    438 \n    439     except Exception as e:\n    440         # Note fit time as time until error\n    441         fit_time = time.time() - start_time\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=3, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=0), X=array([[  0.,   0.,   0., ...,   3.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), y=array([0, 2, 2, ..., 8, 9, 8]), groups=None, **fit_params={})\n    633                                   return_train_score=self.return_train_score,\n    634                                   return_n_test_samples=True,\n    635                                   return_times=True, return_parameters=False,\n    636                                   error_score=self.error_score)\n    637           for parameters, (train, test) in product(candidate_params,\n--> 638                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = array([[  0.,   0.,   0., ...,   3.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]])\n        y = array([0, 2, 2, ..., 8, 9, 8])\n        groups = None\n    639 \n    640         # if one choose to see train score, \"out\" will contain train score info\n    641         if self.return_train_score:\n    642             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=-1)>\n        iterator = <generator object BaseSearchCV.fit.<locals>.<genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=-1), iterator=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=-1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=-1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), array([[  0.,   0.,   0., ...,   3.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), array([0, 2, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 384,  390,  395,  397,  398,  402,  403,...1188, 1189, 1190, 1191, 1192, 1193,\n       1194]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...94, 396, 399, 400, 401, 404, 407, 408, 409, 410]), 0, {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), array([[  0.,   0.,   0., ...,   3.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), array([0, 2, 2, ..., 8, 9, 8]), {'score': <function _passthrough_scorer>}, array([ 384,  390,  395,  397,  398,  402,  403,...1188, 1189, 1190, 1191, 1192, 1193,\n       1194]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...94, 396, 399, 400, 401, 404, 407, 408, 409, 410]), 0, {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), X=array([[  0.,   0.,   0., ...,   3.,   0.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), y=array([0, 2, 2, ..., 8, 9, 8]), scorer={'score': <function _passthrough_scorer>}, train=array([ 384,  390,  395,  397,  398,  402,  403,...1188, 1189, 1190, 1191, 1192, 1193,\n       1194]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...94, 396, 399, 400, 401, 404, 407, 408, 409, 410]), verbose=0, parameters={'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2'}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    432 \n    433     try:\n    434         if y_train is None:\n    435             estimator.fit(X_train, **fit_params)\n    436         else:\n--> 437             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No....0001,\n          verbose=0, warm_start=False))])>\n        X_train = array([[  0.,   3.,  15., ...,  16.,  16.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]])\n        y_train = array([2, 3, 8, 3, 1, 3, 6, 6, 1, 7, 2, 8, 2, 2,...2, 5, 7,\n       9, 5, 4, 8, 8, 4, 9, 0, 8, 9, 8])\n        fit_params = {}\n    438 \n    439     except Exception as e:\n    440         # Note fit time as time until error\n    441         fit_time = time.time() - start_time\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('minmaxscaler...0.0001,\n          verbose=0, warm_start=False))]), X=array([[  0.,   3.,  15., ...,  16.,  16.,   0.]...      [  0.,   0.,  10., ...,  12.,   1.,   0.]]), y=array([2, 3, 8, 3, 1, 3, 6, 6, 1, 7, 2, 8, 2, 2,...2, 5, 7,\n       9, 5, 4, 8, 8, 4, 9, 0, 8, 9, 8]), **fit_params={})\n    254         self : Pipeline\n    255             This estimator\n    256         \"\"\"\n    257         Xt, fit_params = self._fit(X, y, **fit_params)\n    258         if self._final_estimator is not None:\n--> 259             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method LogisticRegression.fit of Logistic...l=0.0001,\n          verbose=0, warm_start=False)>\n        Xt = array([[ 0.    ,  0.375 ,  0.9375, ...,  1.    ,....    ,  0.625 , ...,  0.75  ,  0.0625,  0.    ]])\n        y = array([2, 3, 8, 3, 1, 3, 6, 6, 1, 7, 2, 8, 2, 2,...2, 5, 7,\n       9, 5, 4, 8, 8, 4, 9, 0, 8, 9, 8])\n        fit_params = {}\n    260         return self\n    261 \n    262     def fit_transform(self, X, y=None, **fit_params):\n    263         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py in fit(self=LogisticRegression(C=0.1, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), X=array([[ 0.    ,  0.375 ,  0.9375, ...,  1.    ,....    ,  0.625 , ...,  0.75  ,  0.0625,  0.    ]]), y=array([2, 3, 8, 3, 1, 3, 6, 6, 1, 7, 2, 8, 2, 2,...2, 5, 7,\n       9, 5, 4, 8, 8, 4, 9, 0, 8, 9, 8]), sample_weight=None)\n   1217         check_classification_targets(y)\n   1218         self.classes_ = np.unique(y)\n   1219         n_samples, n_features = X.shape\n   1220 \n   1221         _check_solver_option(self.solver, self.multi_class, self.penalty,\n-> 1222                              self.dual)\n        self.dual = False\n   1223 \n   1224         if self.solver == 'liblinear':\n   1225             if self.n_jobs != 1:\n   1226                 warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n\n...........................................................................\n/Users/henry/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py in _check_solver_option(solver='saga', multi_class='auto', penalty='l2', dual=False)\n    429                          \"newton-cg, lbfgs, sag and saga solvers, got %s\"\n    430                          % solver)\n    431 \n    432     if multi_class not in ['multinomial', 'ovr']:\n    433         raise ValueError(\"multi_class should be either multinomial or \"\n--> 434                          \"ovr, got %s\" % multi_class)\n        multi_class = 'auto'\n    435 \n    436     if multi_class == 'multinomial' and solver == 'liblinear':\n    437         raise ValueError(\"Solver %s does not support \"\n    438                          \"a multinomial backend.\" % solver)\n\nValueError: multi_class should be either multinomial or ovr, got auto\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(),\n",
    "                     LogisticRegression(solver='saga', multi_class='auto', random_state=42, max_iter=5000))\n",
    "param_grid = {'logisticregression__C': [0.1, 1.0, 10],\n",
    "              'logisticregression__penalty': ['l2', 'l1']}\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=3, n_jobs=-1)\n",
    "scores = pd.DataFrame(cross_validate(grid, X, y, cv=3, n_jobs=-1, return_train_score=True))\n",
    "scores[['train_score', 'test_score']].boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
